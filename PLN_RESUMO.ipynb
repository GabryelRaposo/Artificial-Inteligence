{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLN RESUMO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabryelRaposo/Artificial-Inteligence/blob/master/PLN_RESUMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_53mFgwDNpF",
        "outputId": "c67e03d8-d57d-4de4-8c43-6425a45e5c7a"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QULmE7_VDZQZ",
        "outputId": "f9d26ae1-ffe6-431a-fc13-a632329edea1"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('gutenberg')\r\n",
        "nltk.download('genesis')\r\n",
        "nltk.download('inaugural')\r\n",
        "nltk.download('nps_chat')\r\n",
        "nltk.download('webtext')\r\n",
        "nltk.download('treebank')\r\n",
        "from nltk.book import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlNuUtp3EJYd"
      },
      "source": [
        "fdist1 = FreqDist(text1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0nUIxytEKtS",
        "outputId": "dc5141ca-d4d4-44af-a4c1-88b40df575a3"
      },
      "source": [
        "print(fdist1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<FreqDist with 19317 samples and 260819 outcomes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAXz4VEjFFaJ",
        "outputId": "e1d10618-e6fb-4654-b447-bd4bcbcd2e54"
      },
      "source": [
        "V = set(text1)\r\n",
        "long_words = [word for word in V if len(word) > 15]\r\n",
        "print(long_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['circumnavigating', 'characteristically', 'Physiognomically', 'physiognomically', 'uncompromisedness', 'circumnavigation', 'superstitiousness', 'apprehensiveness', 'supernaturalness', 'responsibilities', 'subterraneousness', 'undiscriminating', 'simultaneousness', 'circumnavigations', 'indispensableness', 'CIRCUMNAVIGATION', 'cannibalistically', 'preternaturalness', 'comprehensiveness', 'uninterpenetratingly', 'uncomfortableness', 'hermaphroditical', 'indiscriminately', 'irresistibleness']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BQCxbdBjvW6"
      },
      "source": [
        " saying = ['After', 'all', 'is', 'said', 'and', 'done', 'more', 'is', 'said', 'than', 'done']\r\n",
        "tokens = set(saying)\r\n",
        "tokens = sorted(tokens)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOzAGBWsj8kl",
        "outputId": "4c7fd17b-ad73-4f70-9843-64a39bc65288"
      },
      "source": [
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['After', 'all', 'and', 'done', 'is', 'more', 'said', 'than']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rUPhz99wrju",
        "outputId": "e0fa09b9-5019-4be5-edb6-1acc3d090e34"
      },
      "source": [
        "print(text1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Text: Moby Dick by Herman Melville 1851>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHLA3XtpzofS"
      },
      "source": [
        "\r\n",
        "\r\n",
        "```\r\n",
        "FUNCTIONS                                                 MEANING\r\n",
        "\r\n",
        "s.startswith(t)\t                    test if s starts with t\r\n",
        "s.endswith(t)\t                      test if s ends with t           \r\n",
        "s.islower()                            test if s contains cased characters and all are lowercase\r\n",
        "s.isupper()                            test if s contains cased characters and all are uppercase   \r\n",
        "s.isalpha()\t                        test if s is non-empty and all characters in s are alphabetic\r\n",
        "s.isalnum()\t                        test if s is non-empty and all characters in s are alphanumeric\r\n",
        "s.isdigit()\t                        test if s is non-empty and all characters in s are digits\r\n",
        "s.istitle()                            test if s contains cased characters and is titlecased (i.e. all words in s have initial capitals)\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3au78et2iah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dceadc-71af-4386-d566-4b5725797532"
      },
      "source": [
        "#exemplos\r\n",
        "sorted(w for w in set(text1) if w.endswith('ableness'))\r\n",
        "#['comfortableness', 'honourableness', 'immutableness', 'indispensableness', ...]\r\n",
        "sorted(term for term in set(text4) if 'gnt' in term)\r\n",
        "#['Sovereignty', 'sovereignties', 'sovereignty']\r\n",
        "len(set(word.lower() for word in text1 if word.isalpha()))\r\n",
        "len(set(word.lower() for word in text1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acyVc_kMmQiV"
      },
      "source": [
        "# Capítulo 2. Acessing Text Corpora and lexicais resources\r\n",
        "\r\n",
        "---\r\n",
        "O NLTK inclui uma pequena seleção de textos do arquivo de texto eletrônico do Project Gutenberg, que contém cerca de 25.000 livros eletrônicos gratuitos, hospedados em http://www.gutenberg.org/. Começamos fazendo com que o interpretador Python carregue o pacote NLTK e, em seguida, pedimos para ver nltk.corpus.gutenberg.fileids () , os identificadores de arquivo neste corpus:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6OTtmyykfkJ",
        "outputId": "17519fad-e0fe-4a54-a7ca-b9ab6a591cd3"
      },
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGfOZukfpJvP"
      },
      "source": [
        "from nltk.corpus import gutenberg \r\n",
        "emma = gutenberg.words('austen-emma.txt')\r\n",
        "len(emma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fESCCNdbpUtC",
        "outputId": "fedf0c3a-e24c-4321-e849-0eeb1f0224c1"
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "for fileid in gutenberg.fileids():\r\n",
        "    num_chars = len(gutenberg.raw(fileid)) #função raw diz o numero de letras\r\n",
        "    num_words = len(gutenberg.words(fileid))\r\n",
        "    num_sents = len(gutenberg.sents(fileid))\r\n",
        "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\r\n",
        "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)\r\n",
        "    #media do comprimento das palavras, media do comprimento de sentenças, numero de vezes que cada palavra do vocabulario \r\n",
        "    #aparece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "5 25 26 austen-emma.txt\n",
            "5 26 17 austen-persuasion.txt\n",
            "5 28 22 austen-sense.txt\n",
            "4 34 79 bible-kjv.txt\n",
            "5 19 5 blake-poems.txt\n",
            "4 19 14 bryant-stories.txt\n",
            "4 18 12 burgess-busterbrown.txt\n",
            "4 20 13 carroll-alice.txt\n",
            "5 20 12 chesterton-ball.txt\n",
            "5 23 11 chesterton-brown.txt\n",
            "5 18 11 chesterton-thursday.txt\n",
            "4 21 25 edgeworth-parents.txt\n",
            "5 26 15 melville-moby_dick.txt\n",
            "5 52 11 milton-paradise.txt\n",
            "4 12 9 shakespeare-caesar.txt\n",
            "4 12 8 shakespeare-hamlet.txt\n",
            "4 12 7 shakespeare-macbeth.txt\n",
            "5 36 12 whitman-leaves.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h3Xe2Ojn_U_"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "### Dessa forma, alem da extensão gutenberg, temos a brown,webtext, nps_chat\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "# Considerando BROWN CORPUS\r\n",
        "Temos aqui textos de 500 fontes, categorizados por generos, ou categorias, os texto podem ser acessados por fileids() ou categories()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3jbLbX8eN9a",
        "outputId": "35c971ed-6574-4eaa-efce-75bad505cb45"
      },
      "source": [
        "nltk.download('brown')\r\n",
        "from nltk.corpus import brown\r\n",
        "brown.categories()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewn7r5kZuSeq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgm4SrOEoo4x",
        "outputId": "19ced279-0d19-42d8-e191-5270246ce008"
      },
      "source": [
        "#brown.fileids()\r\n",
        "brown.words(fileids=['cg22'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHwP3Q2yo8kI"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "## OBS:\r\n",
        "\r\n",
        "### We need to include end=' ' in order for the print function to put its output on a single line.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgRlL_J3ozPq"
      },
      "source": [
        "k = nltk.ConditionalFreqDist((genre, word) for genre in brown.categories() for word in brown.words(categories=genre))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x5skaVQsC4P"
      },
      "source": [
        "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\r\n",
        "modals = ['can', 'could', 'may', 'might', 'must', 'will']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOhUCenqsGGj",
        "outputId": "20bc44de-e06c-4e3d-eaba-aea877b8eb51"
      },
      "source": [
        " k.tabulate(conditions=genres, samples=modals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  can could   may might  must  will \n",
            "           news    93    86    66    38    50   389 \n",
            "       religion    82    59    78    12    54    71 \n",
            "        hobbies   268    58   131    22    83   264 \n",
            "science_fiction    16    49     4    12     8    16 \n",
            "        romance    74   193    11    51    45    43 \n",
            "          humor    16    30     8     8     9    13 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjgJUWLEuT0v"
      },
      "source": [
        "kposdffpo"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}